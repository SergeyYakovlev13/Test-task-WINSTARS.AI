import tensorflow as tf

#Defining function for U-Net's encoder.
def encoder(In):
    In=tf.keras.layers.BatchNormalization()(In)  
    x1=tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(In)
    x1=tf.keras.layers.BatchNormalization()(x1)
    x1=tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x1)
    x1=tf.keras.layers.BatchNormalization()(x1)
    x1=tf.keras.layers.MaxPool2D(pool_size=(2,2))(x1)
    x1=tf.keras.layers.BatchNormalization()(x1)
    x2=tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x1)
    x2=tf.keras.layers.BatchNormalization()(x2)
    x2=tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x2)
    x2=tf.keras.layers.BatchNormalization()(x2)
    x2=tf.keras.layers.MaxPool2D(pool_size=(2,2))(x2)
    x2=tf.keras.layers.BatchNormalization()(x2)
    x3=tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x2)
    x3=tf.keras.layers.BatchNormalization()(x3)
    x3=tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x3)
    x3=tf.keras.layers.BatchNormalization()(x3)
    x3=tf.keras.layers.MaxPool2D(pool_size=(2,2))(x3)
    x3=tf.keras.layers.BatchNormalization()(x3)
    x4=tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x3)
    x4=tf.keras.layers.BatchNormalization()(x4)
    x4=tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x4)
    x4=tf.keras.layers.BatchNormalization()(x4)
    x4=tf.keras.layers.MaxPool2D(pool_size=(2,2))(x4)
    x4=tf.keras.layers.BatchNormalization()(x4)
    x5=tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x4)
    x5=tf.keras.layers.BatchNormalization()(x5)
    x5=tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x5)
    x5=tf.keras.layers.BatchNormalization()(x5)
    x5=tf.keras.layers.MaxPool2D(pool_size=(2,2))(x5)
    x5=tf.keras.layers.BatchNormalization()(x5)
    return x1,x2,x3,x4,x5

#Defining function for U-Net's decoder.
def decoder(In,convs):
   f1,f2,f3,f4,f5=convs
   x=tf.keras.layers.Conv2DTranspose(filters=128,kernel_size=(2,2),strides=(2,2),activation=tf.keras.layers.LeakyReLU(0.1),use_bias=False, padding='valid')(f5)
   x=tf.keras.layers.BatchNormalization()(x)
   f4=tf.keras.layers.Conv2D(filters=128,kernel_size=(1,1),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(f4)
   x=tf.keras.layers.Concatenate(axis=-1)([f4,x])
   x=tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   x=tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   x=tf.keras.layers.Conv2DTranspose(filters=64,kernel_size=(2,2),strides=(2,2),activation=tf.keras.layers.LeakyReLU(0.1),use_bias=False, padding='valid')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   f3=tf.keras.layers.Conv2D(filters=64,kernel_size=(1,1),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(f3) 
   x=tf.keras.layers.Concatenate(axis=-1)([f3,x])
   x=tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   x=tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   x=tf.keras.layers.Conv2DTranspose(filters=32,kernel_size=(2,2),strides=(2,2),activation=tf.keras.layers.LeakyReLU(0.1),use_bias=False, padding='valid')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   f2=tf.keras.layers.Conv2D(filters=32,kernel_size=(1,1),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(f2)
   x=tf.keras.layers.Concatenate(axis=-1)([f2,x])
   x=tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   x=tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   x=tf.keras.layers.Conv2DTranspose(filters=16,kernel_size=(2,2),strides=(2,2),activation=tf.keras.layers.LeakyReLU(0.1),use_bias=False, padding='valid')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   f1=tf.keras.layers.Conv2D(filters=16,kernel_size=(1,1),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(f1)
   x=tf.keras.layers.Concatenate(axis=-1)([f1,x])
   x=tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   x=tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   x=tf.keras.layers.Conv2DTranspose(filters=8,kernel_size=(2,2),strides=(2,2),activation=tf.keras.layers.LeakyReLU(0.1),use_bias=False, padding='valid')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   In=tf.keras.layers.Conv2D(filters=8,kernel_size=(1,1),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(In)
   In=tf.keras.layers.BatchNormalization()(In)  
   x=tf.keras.layers.Concatenate(axis=-1)([In,x])
   x=tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   x=tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),activation=tf.keras.layers.LeakyReLU(0.1),padding='same')(x)
   x=tf.keras.layers.BatchNormalization()(x)
   output=tf.keras.layers.Conv2D(filters=1,kernel_size=(1,1),activation='sigmoid')(x)
   return output

#Defining function for complete U-Net model.
def segmentation_model(img_size,n_channels):
    In=tf.keras.Input(shape=(img_size,img_size,n_channels))
    convs=encoder(In)
    Out=decoder(In,convs)
    model=tf.keras.Model(inputs=In,outputs=Out,name='Ship_segmentator')
    return model